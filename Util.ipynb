{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculate the average number of articles per week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from corputil import FileCorpus\n",
    "\n",
    "file1 = path.join('data', 'Corpus_{}.txt'.format('KW44'))\n",
    "file2 = path.join('data', 'Corpus_{}.txt'.format('KW45'))\n",
    "file3 = path.join('data', 'Corpus_{}.txt'.format('KW46'))\n",
    "file4 = path.join('data', 'Corpus_{}.txt'.format('KW47'))\n",
    "file5 = path.join('data', 'Corpus_{}.txt'.format('KW48'))\n",
    "\n",
    "corpus = FileCorpus(file1, file2, file3, file4, file5)\n",
    "list_corpus = [article for article in corpus]\n",
    "\n",
    "print(len(list_corpus) / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from corputil import FileCorpus\n",
    "\n",
    "file1 = path.join('data', 'Corpus_DieLinke.txt')\n",
    "file2 = path.join('data', 'Corpus_DieLinke_PR.txt')\n",
    "\n",
    "corpus1 = FileCorpus(file1)\n",
    "corpus2 = FileCorpus(file2)\n",
    "\n",
    "list1 = [article for article in corpus1]\n",
    "list2 = [article for article in corpus2]\n",
    "print(len(list1))\n",
    "print(len(list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Wikipedia XML dump into a one sentence per line representation for LineSentence from Gensim. LineSentence can then be used as input for word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bz2\n",
    "import nltk\n",
    "from os import path\n",
    "from gensim.corpora.wikicorpus import extract_pages, filter_wiki\n",
    "\n",
    "pattern = re.compile(r'[\\W\\d]')\n",
    "space = re.compile(r'\\s+')\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/german.pickle')\n",
    "wiki_file = path.join('data', 'dewiki-latest-pages-articles.xml.bz2')\n",
    "\n",
    "f = bz2.BZ2File(wiki_file)\n",
    "articles = extract_pages(f)\n",
    "with open(path.join('data', 'Corpus_Wiki.txt'), 'w', encoding='UTF-8') as f:\n",
    "    for title, text, t_id in articles:\n",
    "        text = filter_wiki(text)\n",
    "        sentences = tokenizer.tokenize(text)\n",
    "        for sentence in sentences:\n",
    "            letters_only = pattern.sub(' ', sentence)\n",
    "            letters_only = space.sub(' ', letters_only).strip()\n",
    "            words = letters_only.lower().split()\n",
    "            if len(words) > 10:\n",
    "                f.write(' '.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "lda = LdaModel.load(path.join('models', 'lda', 'KW46.lda'))\n",
    "lda.show_topics(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from os import path\n",
    "from html2corpus import HTML2Corpus\n",
    "from html2corpus.extractors import ReadabilityExtractor\n",
    "\n",
    "link = 'https://www.spd.de/presse/pressemitteilungen/detail/news/heidemarie-wieczorek-zeul-zur-entwicklungszusammenarbeit/2/12/2015/'\n",
    "req = requests.get(link)\n",
    "HTML2Corpus([req.content], extractor=ReadabilityExtractor(min_len=100)).save(path.join('data', 'Test.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
