{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### from gensim import corpora, models, similarities\n",
    "from lxml.etree import XMLSyntaxError, ParserError\n",
    "import os.path as path\n",
    "import sqlite3\n",
    "import justext\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[\\d\\.\\(\\)\\[\\]\\-\\'/:;,\"#&!ยง]', ' ', text)\n",
    "    return re.sub(r' +', ' ', text)\n",
    "\n",
    "# def extract_text(html):\n",
    "#     text = []\n",
    "#     paragraphs = justext.justext(html, justext.get_stoplist('German'))\n",
    "#     for paragraph in paragraphs:\n",
    "#         if not paragraph.is_boilerplate and not paragraph.is_heading:\n",
    "#             text.append(paragraph.text)\n",
    "#     return ' '.join(text)\n",
    "\n",
    "# def gen(data):\n",
    "#     for row in data:\n",
    "#         title, summary, html = row\n",
    "#         try:\n",
    "#             text = extract_text(html)\n",
    "#             text = clean_text(text)\n",
    "#             yield (title, summary, text)\n",
    "#         except XMLSyntaxError as error:\n",
    "#             yield ('', '', '')\n",
    "#         except ParserError as error:\n",
    "#             yield ('', '', '')\n",
    "\n",
    "def read_corpus(data):\n",
    "    acc = []\n",
    "    for i, p in data:\n",
    "        acc.append(dictionary.get(i))\n",
    "    print(' '.join(acc))\n",
    "\n",
    "def read_results(data, n):\n",
    "    sims = sorted(enumerate(data), key=lambda item: -item[1])\n",
    "    for i, p in sims[:n]:\n",
    "        read_corpus(corpus[i])\n",
    "        print('#####################')\n",
    "\n",
    "dictionary = corpora.Dictionary.load('corpus.dict')\n",
    "corpus = corpora.MmCorpus('corpus.mm')\n",
    "lda = models.LdaModel.load('model.lda')\n",
    "index = similarities.MatrixSimilarity.load('model.index')\n",
    "\n",
    "# sql_query = 'SELECT title, summary, html FROM Sources LEFT JOIN Articles ON Sources.id = Articles.source LIMIT 10'\n",
    "\n",
    "# db_file = path.join('..', 'Crawler', 'Data', 'GermanNews.sqlite')\n",
    "# conn = sqlite3.connect(db_file)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# cursor.execute(sql_query)\n",
    "# data = cursor.fetchmany(10)\n",
    "        \n",
    "# for title, summary, text in gen(data):\n",
    "#     bow = dictionary.doc2bow(text.lower().split())\n",
    "#     inf = lda[bow]\n",
    "#     topics = []\n",
    "#     for i, p in inf:\n",
    "#         topics.append(dictionary.get(i, 'EMPTY'))\n",
    "#     print('\\n Title: {}\\n Summary: {}\\n Topics: {}'.format(title, summary, ', '.join(topics)))\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search = 'Angela Merkel'\n",
    "# search = clean_text(search)\n",
    "# bow = dictionary.doc2bow(search.lower().split())\n",
    "# search_lda = lda[bow]\n",
    "# found = index[search_lda]\n",
    "\n",
    "# read_results(found, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
