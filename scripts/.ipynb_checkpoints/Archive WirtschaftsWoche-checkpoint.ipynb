{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import logging\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from os import path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "fh = logging.FileHandler(path.join('..', 'logs', 'wiwo_crawler.log'))\n",
    "fh.setLevel(logging.ERROR)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_file = path.join('..', '..', 'Crawler', 'data', 'archive_wirtschaftswoche.sqlite')\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sql_insert = 'INSERT INTO WirtschaftsWoche (title, date, tag, url, html) VALUES (?, ?, ?, ?, ?)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domain = 'http://www.wiwo.de'\n",
    "\n",
    "start = dt.date(2004, 1, 1)\n",
    "end = dt.datetime.now()\n",
    "dates = pd.date_range(start, end)\n",
    "urls = ['{}/archiv/{}'.format(domain, date.strftime('%Y/%m/%d')) for date in dates]\n",
    "dates = [date.to_pydatetime() for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_url(url):\n",
    "    if url.startswith('/'):\n",
    "        return ''.join([domain, url])\n",
    "    else:\n",
    "        return url\n",
    "    \n",
    "def extract_tag(url):\n",
    "    tags = url.split('/')\n",
    "    return tags[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for url, date in zip(urls, dates):\n",
    "    data = []\n",
    "    try:\n",
    "        req = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(req.content)\n",
    "        articles = soup.find('ul', class_='hcf-headline-list')\n",
    "        for article in articles.find_all('li'):\n",
    "            article_url = generate_url(article.a.get('href'))\n",
    "            tag = extract_tag(article_url)\n",
    "            title = article.a.get('title')\n",
    "            try:\n",
    "                html = requests.get(article_url, stream=True, timeout=10).content\n",
    "                data.append( (title, date, tag, article_url, html) )\n",
    "            except RequestException as error:\n",
    "                logger.error('ARTICLE FAIL: %s : %s, %s', error, article_url, date)\n",
    "        cursor.executemany(sql_insert, data)\n",
    "        conn.commit()\n",
    "    except RequestException as error:\n",
    "        logger.error('DAY FAIL: %s : %s, %s', error, url, date)\n",
    "    except AttributeError as error:\n",
    "        logger.error('DAY FAIL: %s : %s, %s', error, url, date)\n",
    "    else:\n",
    "        logger.debug('Successfully crawled articles from: %s', date)\n",
    "    time.sleep(2)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
