{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Political Opinion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "from os import path\n",
    "from random import shuffle\n",
    "from corputil import FileCorpus, ListCorpus\n",
    "from corputil.utils import load_stopwords\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "\n",
    "stopwords = load_stopwords(path.join('data', 'german.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Base Model\n",
    "\n",
    "Calculate the base model (empty), that is later used as a base for training the classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 79560 words, keeping 18381 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 163159 words, keeping 27959 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 237379 words, keeping 36911 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 309087 words, keeping 43507 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 386437 words, keeping 50594 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 468583 words, keeping 56982 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 548054 words, keeping 62117 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 628164 words, keeping 66551 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 708074 words, keeping 70985 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 789140 words, keeping 75246 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 870449 words, keeping 79208 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 951887 words, keeping 82905 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 1014764 words, keeping 88839 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 1072815 words, keeping 94372 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 1135710 words, keeping 100179 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 1204767 words, keeping 104407 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 1268317 words, keeping 107697 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 1323446 words, keeping 109962 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 1384782 words, keeping 113095 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 1456767 words, keeping 116810 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 1529308 words, keeping 119676 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 1610532 words, keeping 122874 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 1689316 words, keeping 126352 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 1742805 words, keeping 128426 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 1797845 words, keeping 130600 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 1853683 words, keeping 132430 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 1899098 words, keeping 133867 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 1949010 words, keeping 134596 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 2002481 words, keeping 134596 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 2058698 words, keeping 134859 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #310000, processed 2112811 words, keeping 134943 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #320000, processed 2159592 words, keeping 135216 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #330000, processed 2213270 words, keeping 136190 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #340000, processed 2266127 words, keeping 137381 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #350000, processed 2321207 words, keeping 138605 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #360000, processed 2376578 words, keeping 139804 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #370000, processed 2437633 words, keeping 141326 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #380000, processed 2492467 words, keeping 142830 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #390000, processed 2543141 words, keeping 144139 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #400000, processed 2598441 words, keeping 145653 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #410000, processed 2654564 words, keeping 147363 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #420000, processed 2709220 words, keeping 148862 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #430000, processed 2762895 words, keeping 150075 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #440000, processed 2819530 words, keeping 151481 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #450000, processed 2879364 words, keeping 153347 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #460000, processed 2938162 words, keeping 154786 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #470000, processed 2996274 words, keeping 156198 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #480000, processed 3053673 words, keeping 157789 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #490000, processed 3114337 words, keeping 159634 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #500000, processed 3175448 words, keeping 161528 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #510000, processed 3241711 words, keeping 163648 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #520000, processed 3308222 words, keeping 165738 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #530000, processed 3374058 words, keeping 167793 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #540000, processed 3442122 words, keeping 169958 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #550000, processed 3509432 words, keeping 171200 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #560000, processed 3571318 words, keeping 172238 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #570000, processed 3638165 words, keeping 173408 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #580000, processed 3705865 words, keeping 175569 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #590000, processed 3774750 words, keeping 177150 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #600000, processed 3872419 words, keeping 181649 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #610000, processed 3982729 words, keeping 187091 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #620000, processed 4092529 words, keeping 192315 word types\n",
      "INFO:gensim.models.word2vec:collected 193466 word types from a corpus of 4124883 raw words and 623004 sentences\n",
      "INFO:gensim.models.word2vec:min_count=5 retains 57420 unique words (drops 136046)\n",
      "INFO:gensim.models.word2vec:min_count leaves 3898849 word corpus (94% of original 4124883)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 193466 items\n",
      "INFO:gensim.models.word2vec:sample=0 downsamples 0 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 3898849 word corpus (100.0% of prior 3898849)\n",
      "INFO:gensim.models.word2vec:estimated required memory for 57420 words and 200 dimensions: 132066000 bytes\n",
      "INFO:gensim.models.word2vec:constructing a huffman tree from 57420 words\n",
      "INFO:gensim.models.word2vec:built huffman tree with maximum node depth 20\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "spd = [\n",
    "    path.join('data', 'Politics', 'SPD_EU.txt'),\n",
    "    path.join('data', 'Politics', 'SPD_Fraktion.txt'),\n",
    "#     path.join('data', 'Politics', 'SPD_Vorwärts_Inland.txt'),\n",
    "#     path.join('data', 'Politics', 'SPD_Vorwärts_International.txt'),\n",
    "    path.join('data', 'Politics', 'SPD_Vorwärts_Parteileben.txt')\n",
    "]\n",
    "\n",
    "linke = [\n",
    "    path.join('data', 'Politics', 'Linke.txt'),\n",
    "    path.join('data', 'Politics', 'Linke_PR.txt')\n",
    "#     path.join('data', 'Politics', 'Linke_Fraktion.txt')\n",
    "]\n",
    "\n",
    "gruene = [\n",
    "    path.join('data', 'Politics', 'Grüne.txt')\n",
    "#     path.join('data', 'Politics', 'Grüne_Fraktion.txt')\n",
    "]\n",
    "\n",
    "fdp = [\n",
    "    path.join('data', 'Politics', 'FDP.txt'),\n",
    "    path.join('data', 'Politics', 'FDP_Fraktion.txt')\n",
    "]\n",
    "\n",
    "cdu = [\n",
    "    path.join('data', 'Politics', 'CDU.txt')\n",
    "#     path.join('data', 'Politics', 'CDU_Fraktion.txt')\n",
    "]\n",
    "\n",
    "npd = [\n",
    "#     path.join('data', 'Politics', 'NPD_MV.txt'),\n",
    "    path.join('data', 'Politics', 'NPD_Sachsen.txt')\n",
    "#     path.join('data', 'Politics', 'NPD_Jung.txt')\n",
    "]\n",
    "\n",
    "files = [file for fp in [spd, linke, gruene, fdp, cdu, npd] for file in fp]\n",
    "\n",
    "base_corpus = list(FileCorpus(files).sentences_token(stopwords=stopwords))\n",
    "base = Word2Vec(workers=4, iter=6, size=200, window=3)\n",
    "base.build_vocab(base_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to disk. Don't finalize the model because we need to train it with new data later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base.save(path.join('models', 'base.w2v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 12.74% examples, 336436 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 25.69% examples, 339647 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 38.64% examples, 340739 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 51.53% examples, 341171 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.48% examples, 341469 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 76.95% examples, 339376 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 89.88% examples, 339783 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 2816490 raw words took 7.8s, 339896 trained words/s\n",
      "INFO:gensim.models.word2vec:training model with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.53% examples, 351510 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 11.16% examples, 353613 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 16.77% examples, 354720 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 22.38% examples, 355134 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 28.00% examples, 355190 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 33.45% examples, 353806 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 39.05% examples, 354041 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 44.68% examples, 354336 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 50.31% examples, 354885 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 55.90% examples, 354878 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 61.38% examples, 353990 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 66.96% examples, 354102 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 72.54% examples, 354164 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 78.15% examples, 354194 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 83.72% examples, 354283 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 89.22% examples, 353986 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 94.86% examples, 354120 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 6765966 raw words took 17.9s, 354704 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded corpus with 69350 sentences.\n",
      "Loaded corpus with 148844 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 70.74% examples, 361868 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 545634 raw words took 1.4s, 360116 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 11592 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 2.78% examples, 329816 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.52% examples, 328916 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8.27% examples, 328794 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 11.03% examples, 328584 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 13.71% examples, 326981 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 16.45% examples, 327192 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 19.20% examples, 327200 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 21.96% examples, 327429 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 24.72% examples, 327784 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 27.48% examples, 327769 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 30.15% examples, 326993 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 32.92% examples, 327265 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 35.70% examples, 327509 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 38.45% examples, 327549 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 41.21% examples, 327693 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 43.86% examples, 326954 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 46.60% examples, 326963 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 49.36% examples, 327130 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 52.18% examples, 327567 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 54.99% examples, 327932 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 57.74% examples, 327996 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 60.43% examples, 327618 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 62.97% examples, 326510 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 65.65% examples, 326293 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 68.44% examples, 326468 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 71.16% examples, 326428 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 73.85% examples, 326250 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 76.59% examples, 326233 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 79.36% examples, 326403 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 82.10% examples, 326409 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 84.84% examples, 326470 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 87.52% examples, 326262 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 90.14% examples, 325834 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 92.86% examples, 325776 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 95.58% examples, 325753 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 98.30% examples, 325679 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 12515094 raw words took 36.7s, 325497 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 360090 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 119214 raw words took 0.3s, 329550 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 2790 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 20.66% examples, 374955 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 41.48% examples, 375115 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 61.97% examples, 374137 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 82.51% examples, 373727 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 1986900 raw words took 4.9s, 374128 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 30338 sentences.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "corpora = [\n",
    "    FileCorpus(linke),\n",
    "    FileCorpus(spd),\n",
    "    FileCorpus(gruene), \n",
    "    FileCorpus(fdp), \n",
    "    FileCorpus(cdu), \n",
    "    FileCorpus(npd)\n",
    "]\n",
    "models = [deepcopy(base) for i in range(len(corpora))]\n",
    "\n",
    "for i in range(len(corpora)):\n",
    "    sentences = list(corpora[i].sentences_token(stopwords=stopwords))\n",
    "    shuffle(sentences)\n",
    "    models[i].train(sentences, total_examples=len(sentences))\n",
    "    print('Loaded corpus with {} sentences.'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['2015KW44', '2015KW45', '2015KW46', '2015KW47', '2015KW48', '2015KW49', '2015KW50', '2015KW51', \n",
    "          '2015KW52', '2015KW53', '2016KW01']\n",
    "files = [path.join('data', 'CurrentNews', '{}.csv').format(label) for label in labels]\n",
    "output = [path.join('data', 'CurrentNews', 'Sentiment_{}.csv').format(label) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 93625 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 89873 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 90210 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 90168 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 90873 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 92422 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.7s, 86618 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.7s, 89380 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.7s, 92367 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.7s, 87564 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.8s, 82581 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.7s, 86451 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9270000.00% sentences, 92691 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.2s, 93373 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9210000.00% sentences, 92061 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.2s, 92398 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9330000.00% sentences, 93036 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.2s, 92646 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9190000.00% sentences, 91863 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.2s, 91196 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9250000.00% sentences, 92443 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.2s, 92170 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9180000.00% sentences, 91800 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.2s, 92020 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9620000.00% sentences, 95862 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.1s, 95846 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8970000.00% sentences, 89567 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 11 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.2s, 88104 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8970000.00% sentences, 89659 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.2s, 89179 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8920000.00% sentences, 89110 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.2s, 88575 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8680000.00% sentences, 86793 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.2s, 87082 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8690000.00% sentences, 86891 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.2s, 87161 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 86296 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.9s, 83785 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 89807 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 88070 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 87388 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 88847 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 83414 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 81679 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 84232 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 81183 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 78772 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.7s, 89049 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.8s, 85968 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.8s, 88211 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.8s, 92277 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.8s, 91167 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.8s, 90795 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.8s, 93813 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 94891 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 91002 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 94341 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 93153 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 92699 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 95235 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 95167 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.6s, 81829 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.6s, 83050 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.6s, 85571 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 92168 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 87343 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.6s, 94259 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.6s, 87274 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.6s, 93012 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.7s, 78480 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.6s, 90937 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.6s, 94284 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 93959 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.9s, 89334 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 92974 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.9s, 91331 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 94529 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 57420 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 93984 sentences/s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_score(doc, mod):\n",
    "    model = Word2Vec.load(mod)\n",
    "    score = model.score(doc, len(doc))\n",
    "    return score\n",
    "\n",
    "def calc_probability(df, mods):\n",
    "    docs = list(ListCorpus(list(df.loc[:, 'text'])).doc_sentences_token(stopwords=stopwords))\n",
    "    sentlist = [s for d in docs for s in d]\n",
    "    llhd = np.array( [ m.score(sentlist, len(sentlist)) for m in mods ] )\n",
    "    lhd = np.exp(llhd - llhd.max(axis=0))\n",
    "    prob = pd.DataFrame( (lhd/lhd.sum(axis=0)).transpose() )\n",
    "    prob[\"doc\"] = [i for i,d in enumerate(docs) for s in d]\n",
    "    prob = prob.groupby(\"doc\").mean()\n",
    "    return prob\n",
    "\n",
    "def process(data):\n",
    "    sentiment = calc_probability(data, models)\n",
    "    return sentiment\n",
    "\n",
    "# KW = pd.read_csv(path.join('data', 'CurrentNews', '2015KW45.csv'), sep='|', encoding='utf-8')\n",
    "# prob = calc_probability(KW, models)\n",
    "# # prob = prob.div(prob.sum(axis=1), axis=0)\n",
    "# # prob = prob.sub(.16, axis=0)\n",
    "# KW = pd.concat([KW, prob], axis=1)\n",
    "\n",
    "for file, out in zip(files, output):\n",
    "    data = pd.read_csv(file, sep='|', encoding='utf-8')\n",
    "    sentiment = process(data)\n",
    "    csv = pd.concat([data, sentiment], axis=1)\n",
    "    csv.rename(columns={ 0: 'Linke', 1: 'SPD', 2: 'Gruene', 3: 'FDP', 4: 'CDU', 5: 'NPD'  }, inplace=True)\n",
    "    csv.to_csv(out, index=False, encoding='utf-8', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deutsche Stimme</th>\n",
       "      <td>0.136490</td>\n",
       "      <td>0.180363</td>\n",
       "      <td>0.057929</td>\n",
       "      <td>0.043724</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.462288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAZ</th>\n",
       "      <td>0.184752</td>\n",
       "      <td>0.150003</td>\n",
       "      <td>0.148114</td>\n",
       "      <td>0.175101</td>\n",
       "      <td>0.193762</td>\n",
       "      <td>0.148267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focus</th>\n",
       "      <td>0.169547</td>\n",
       "      <td>0.130964</td>\n",
       "      <td>0.122636</td>\n",
       "      <td>0.168041</td>\n",
       "      <td>0.208372</td>\n",
       "      <td>0.200440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frankfurter Rundschau</th>\n",
       "      <td>0.129218</td>\n",
       "      <td>0.140776</td>\n",
       "      <td>0.118108</td>\n",
       "      <td>0.161955</td>\n",
       "      <td>0.229791</td>\n",
       "      <td>0.220151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golem</th>\n",
       "      <td>0.071534</td>\n",
       "      <td>0.240318</td>\n",
       "      <td>0.148460</td>\n",
       "      <td>0.184591</td>\n",
       "      <td>0.252520</td>\n",
       "      <td>0.102577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handelsblatt</th>\n",
       "      <td>0.158400</td>\n",
       "      <td>0.170878</td>\n",
       "      <td>0.120105</td>\n",
       "      <td>0.186125</td>\n",
       "      <td>0.220401</td>\n",
       "      <td>0.144091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heise</th>\n",
       "      <td>0.074142</td>\n",
       "      <td>0.231459</td>\n",
       "      <td>0.123365</td>\n",
       "      <td>0.183150</td>\n",
       "      <td>0.282255</td>\n",
       "      <td>0.105629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huffington Post</th>\n",
       "      <td>0.165205</td>\n",
       "      <td>0.135719</td>\n",
       "      <td>0.142669</td>\n",
       "      <td>0.194036</td>\n",
       "      <td>0.202438</td>\n",
       "      <td>0.159933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Freiheit</th>\n",
       "      <td>0.136850</td>\n",
       "      <td>0.166938</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0.162837</td>\n",
       "      <td>0.171191</td>\n",
       "      <td>0.266749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Welt</th>\n",
       "      <td>0.252063</td>\n",
       "      <td>0.130522</td>\n",
       "      <td>0.135909</td>\n",
       "      <td>0.136008</td>\n",
       "      <td>0.186780</td>\n",
       "      <td>0.158717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N24</th>\n",
       "      <td>0.165508</td>\n",
       "      <td>0.158057</td>\n",
       "      <td>0.150944</td>\n",
       "      <td>0.170977</td>\n",
       "      <td>0.211658</td>\n",
       "      <td>0.142856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTV</th>\n",
       "      <td>0.167361</td>\n",
       "      <td>0.143902</td>\n",
       "      <td>0.130988</td>\n",
       "      <td>0.177364</td>\n",
       "      <td>0.197742</td>\n",
       "      <td>0.182644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netzpolitik</th>\n",
       "      <td>0.096772</td>\n",
       "      <td>0.318177</td>\n",
       "      <td>0.101613</td>\n",
       "      <td>0.185381</td>\n",
       "      <td>0.188937</td>\n",
       "      <td>0.109119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP Online</th>\n",
       "      <td>0.184158</td>\n",
       "      <td>0.144390</td>\n",
       "      <td>0.116414</td>\n",
       "      <td>0.192778</td>\n",
       "      <td>0.197568</td>\n",
       "      <td>0.164691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.166198</td>\n",
       "      <td>0.145768</td>\n",
       "      <td>0.140544</td>\n",
       "      <td>0.181115</td>\n",
       "      <td>0.197573</td>\n",
       "      <td>0.168803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stern</th>\n",
       "      <td>0.208711</td>\n",
       "      <td>0.139887</td>\n",
       "      <td>0.132043</td>\n",
       "      <td>0.162430</td>\n",
       "      <td>0.201493</td>\n",
       "      <td>0.155435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Süddeutsche</th>\n",
       "      <td>0.149478</td>\n",
       "      <td>0.133961</td>\n",
       "      <td>0.145046</td>\n",
       "      <td>0.169530</td>\n",
       "      <td>0.238026</td>\n",
       "      <td>0.163960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAZ</th>\n",
       "      <td>0.181355</td>\n",
       "      <td>0.140149</td>\n",
       "      <td>0.141504</td>\n",
       "      <td>0.182557</td>\n",
       "      <td>0.189169</td>\n",
       "      <td>0.165265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesschau</th>\n",
       "      <td>0.148268</td>\n",
       "      <td>0.162393</td>\n",
       "      <td>0.158828</td>\n",
       "      <td>0.210746</td>\n",
       "      <td>0.196247</td>\n",
       "      <td>0.123519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesspiegel</th>\n",
       "      <td>0.156140</td>\n",
       "      <td>0.189322</td>\n",
       "      <td>0.130122</td>\n",
       "      <td>0.178310</td>\n",
       "      <td>0.209327</td>\n",
       "      <td>0.136780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telepolis</th>\n",
       "      <td>0.210559</td>\n",
       "      <td>0.109040</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>0.144556</td>\n",
       "      <td>0.217449</td>\n",
       "      <td>0.178849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welt</th>\n",
       "      <td>0.158430</td>\n",
       "      <td>0.160087</td>\n",
       "      <td>0.138253</td>\n",
       "      <td>0.175559</td>\n",
       "      <td>0.207722</td>\n",
       "      <td>0.159949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WirtschaftsWoche</th>\n",
       "      <td>0.147646</td>\n",
       "      <td>0.145727</td>\n",
       "      <td>0.135425</td>\n",
       "      <td>0.203330</td>\n",
       "      <td>0.233389</td>\n",
       "      <td>0.134483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeit</th>\n",
       "      <td>0.168913</td>\n",
       "      <td>0.156045</td>\n",
       "      <td>0.130885</td>\n",
       "      <td>0.198294</td>\n",
       "      <td>0.188900</td>\n",
       "      <td>0.156963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1         2         3         4  \\\n",
       "site                                                                      \n",
       "Deutsche Stimme        0.136490  0.180363  0.057929  0.043724  0.119205   \n",
       "FAZ                    0.184752  0.150003  0.148114  0.175101  0.193762   \n",
       "Focus                  0.169547  0.130964  0.122636  0.168041  0.208372   \n",
       "Frankfurter Rundschau  0.129218  0.140776  0.118108  0.161955  0.229791   \n",
       "Golem                  0.071534  0.240318  0.148460  0.184591  0.252520   \n",
       "Handelsblatt           0.158400  0.170878  0.120105  0.186125  0.220401   \n",
       "Heise                  0.074142  0.231459  0.123365  0.183150  0.282255   \n",
       "Huffington Post        0.165205  0.135719  0.142669  0.194036  0.202438   \n",
       "Junge Freiheit         0.136850  0.166938  0.095435  0.162837  0.171191   \n",
       "Junge Welt             0.252063  0.130522  0.135909  0.136008  0.186780   \n",
       "N24                    0.165508  0.158057  0.150944  0.170977  0.211658   \n",
       "NTV                    0.167361  0.143902  0.130988  0.177364  0.197742   \n",
       "Netzpolitik            0.096772  0.318177  0.101613  0.185381  0.188937   \n",
       "RP Online              0.184158  0.144390  0.116414  0.192778  0.197568   \n",
       "Spiegel                0.166198  0.145768  0.140544  0.181115  0.197573   \n",
       "Stern                  0.208711  0.139887  0.132043  0.162430  0.201493   \n",
       "Süddeutsche            0.149478  0.133961  0.145046  0.169530  0.238026   \n",
       "TAZ                    0.181355  0.140149  0.141504  0.182557  0.189169   \n",
       "Tagesschau             0.148268  0.162393  0.158828  0.210746  0.196247   \n",
       "Tagesspiegel           0.156140  0.189322  0.130122  0.178310  0.209327   \n",
       "Telepolis              0.210559  0.109040  0.139548  0.144556  0.217449   \n",
       "Welt                   0.158430  0.160087  0.138253  0.175559  0.207722   \n",
       "WirtschaftsWoche       0.147646  0.145727  0.135425  0.203330  0.233389   \n",
       "Zeit                   0.168913  0.156045  0.130885  0.198294  0.188900   \n",
       "\n",
       "                              5  \n",
       "site                             \n",
       "Deutsche Stimme        0.462288  \n",
       "FAZ                    0.148267  \n",
       "Focus                  0.200440  \n",
       "Frankfurter Rundschau  0.220151  \n",
       "Golem                  0.102577  \n",
       "Handelsblatt           0.144091  \n",
       "Heise                  0.105629  \n",
       "Huffington Post        0.159933  \n",
       "Junge Freiheit         0.266749  \n",
       "Junge Welt             0.158717  \n",
       "N24                    0.142856  \n",
       "NTV                    0.182644  \n",
       "Netzpolitik            0.109119  \n",
       "RP Online              0.164691  \n",
       "Spiegel                0.168803  \n",
       "Stern                  0.155435  \n",
       "Süddeutsche            0.163960  \n",
       "TAZ                    0.165265  \n",
       "Tagesschau             0.123519  \n",
       "Tagesspiegel           0.136780  \n",
       "Telepolis              0.178849  \n",
       "Welt                   0.159949  \n",
       "WirtschaftsWoche       0.134483  \n",
       "Zeit                   0.156963  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KW.groupby('site').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deutsche Stimme</th>\n",
       "      <td>0.136490</td>\n",
       "      <td>0.180363</td>\n",
       "      <td>0.057929</td>\n",
       "      <td>0.043724</td>\n",
       "      <td>0.119205</td>\n",
       "      <td>0.462288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAZ</th>\n",
       "      <td>0.168340</td>\n",
       "      <td>0.142580</td>\n",
       "      <td>0.147157</td>\n",
       "      <td>0.177375</td>\n",
       "      <td>0.193305</td>\n",
       "      <td>0.125277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focus</th>\n",
       "      <td>0.156201</td>\n",
       "      <td>0.134349</td>\n",
       "      <td>0.115172</td>\n",
       "      <td>0.144879</td>\n",
       "      <td>0.212745</td>\n",
       "      <td>0.154171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frankfurter Rundschau</th>\n",
       "      <td>0.124845</td>\n",
       "      <td>0.142616</td>\n",
       "      <td>0.102011</td>\n",
       "      <td>0.161611</td>\n",
       "      <td>0.226843</td>\n",
       "      <td>0.154091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golem</th>\n",
       "      <td>0.074822</td>\n",
       "      <td>0.224260</td>\n",
       "      <td>0.135213</td>\n",
       "      <td>0.158004</td>\n",
       "      <td>0.249627</td>\n",
       "      <td>0.086722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handelsblatt</th>\n",
       "      <td>0.152480</td>\n",
       "      <td>0.154918</td>\n",
       "      <td>0.115809</td>\n",
       "      <td>0.157317</td>\n",
       "      <td>0.229697</td>\n",
       "      <td>0.143778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heise</th>\n",
       "      <td>0.080255</td>\n",
       "      <td>0.235726</td>\n",
       "      <td>0.119437</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>0.289699</td>\n",
       "      <td>0.106492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huffington Post</th>\n",
       "      <td>0.144110</td>\n",
       "      <td>0.122674</td>\n",
       "      <td>0.126317</td>\n",
       "      <td>0.179515</td>\n",
       "      <td>0.195330</td>\n",
       "      <td>0.130732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Freiheit</th>\n",
       "      <td>0.122741</td>\n",
       "      <td>0.167613</td>\n",
       "      <td>0.087083</td>\n",
       "      <td>0.127178</td>\n",
       "      <td>0.146592</td>\n",
       "      <td>0.240273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Welt</th>\n",
       "      <td>0.207659</td>\n",
       "      <td>0.117422</td>\n",
       "      <td>0.126253</td>\n",
       "      <td>0.129251</td>\n",
       "      <td>0.179570</td>\n",
       "      <td>0.141422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N24</th>\n",
       "      <td>0.148473</td>\n",
       "      <td>0.152370</td>\n",
       "      <td>0.142108</td>\n",
       "      <td>0.145414</td>\n",
       "      <td>0.220069</td>\n",
       "      <td>0.113308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTV</th>\n",
       "      <td>0.141122</td>\n",
       "      <td>0.138835</td>\n",
       "      <td>0.118584</td>\n",
       "      <td>0.168283</td>\n",
       "      <td>0.174983</td>\n",
       "      <td>0.151392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netzpolitik</th>\n",
       "      <td>0.114816</td>\n",
       "      <td>0.293869</td>\n",
       "      <td>0.103813</td>\n",
       "      <td>0.139316</td>\n",
       "      <td>0.212199</td>\n",
       "      <td>0.096869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP Online</th>\n",
       "      <td>0.172233</td>\n",
       "      <td>0.138998</td>\n",
       "      <td>0.118178</td>\n",
       "      <td>0.195537</td>\n",
       "      <td>0.188413</td>\n",
       "      <td>0.119119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.141179</td>\n",
       "      <td>0.138317</td>\n",
       "      <td>0.135347</td>\n",
       "      <td>0.175481</td>\n",
       "      <td>0.189416</td>\n",
       "      <td>0.131184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stern</th>\n",
       "      <td>0.199719</td>\n",
       "      <td>0.127444</td>\n",
       "      <td>0.134256</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.232304</td>\n",
       "      <td>0.125212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Süddeutsche</th>\n",
       "      <td>0.127118</td>\n",
       "      <td>0.127829</td>\n",
       "      <td>0.139485</td>\n",
       "      <td>0.159392</td>\n",
       "      <td>0.229603</td>\n",
       "      <td>0.130238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAZ</th>\n",
       "      <td>0.164951</td>\n",
       "      <td>0.133685</td>\n",
       "      <td>0.139109</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0.179049</td>\n",
       "      <td>0.119188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesschau</th>\n",
       "      <td>0.127219</td>\n",
       "      <td>0.154068</td>\n",
       "      <td>0.139368</td>\n",
       "      <td>0.191074</td>\n",
       "      <td>0.190624</td>\n",
       "      <td>0.100108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesspiegel</th>\n",
       "      <td>0.156401</td>\n",
       "      <td>0.169185</td>\n",
       "      <td>0.118994</td>\n",
       "      <td>0.166775</td>\n",
       "      <td>0.206165</td>\n",
       "      <td>0.110606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telepolis</th>\n",
       "      <td>0.177044</td>\n",
       "      <td>0.110898</td>\n",
       "      <td>0.137713</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.216360</td>\n",
       "      <td>0.148459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welt</th>\n",
       "      <td>0.149929</td>\n",
       "      <td>0.135790</td>\n",
       "      <td>0.129040</td>\n",
       "      <td>0.165433</td>\n",
       "      <td>0.207596</td>\n",
       "      <td>0.104321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WirtschaftsWoche</th>\n",
       "      <td>0.139183</td>\n",
       "      <td>0.131794</td>\n",
       "      <td>0.126319</td>\n",
       "      <td>0.178989</td>\n",
       "      <td>0.221659</td>\n",
       "      <td>0.110911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeit</th>\n",
       "      <td>0.170910</td>\n",
       "      <td>0.134542</td>\n",
       "      <td>0.115151</td>\n",
       "      <td>0.179987</td>\n",
       "      <td>0.179531</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1         2         3         4  \\\n",
       "site                                                                      \n",
       "Deutsche Stimme        0.136490  0.180363  0.057929  0.043724  0.119205   \n",
       "FAZ                    0.168340  0.142580  0.147157  0.177375  0.193305   \n",
       "Focus                  0.156201  0.134349  0.115172  0.144879  0.212745   \n",
       "Frankfurter Rundschau  0.124845  0.142616  0.102011  0.161611  0.226843   \n",
       "Golem                  0.074822  0.224260  0.135213  0.158004  0.249627   \n",
       "Handelsblatt           0.152480  0.154918  0.115809  0.157317  0.229697   \n",
       "Heise                  0.080255  0.235726  0.119437  0.194606  0.289699   \n",
       "Huffington Post        0.144110  0.122674  0.126317  0.179515  0.195330   \n",
       "Junge Freiheit         0.122741  0.167613  0.087083  0.127178  0.146592   \n",
       "Junge Welt             0.207659  0.117422  0.126253  0.129251  0.179570   \n",
       "N24                    0.148473  0.152370  0.142108  0.145414  0.220069   \n",
       "NTV                    0.141122  0.138835  0.118584  0.168283  0.174983   \n",
       "Netzpolitik            0.114816  0.293869  0.103813  0.139316  0.212199   \n",
       "RP Online              0.172233  0.138998  0.118178  0.195537  0.188413   \n",
       "Spiegel                0.141179  0.138317  0.135347  0.175481  0.189416   \n",
       "Stern                  0.199719  0.127444  0.134256  0.141500  0.232304   \n",
       "Süddeutsche            0.127118  0.127829  0.139485  0.159392  0.229603   \n",
       "TAZ                    0.164951  0.133685  0.139109  0.179947  0.179049   \n",
       "Tagesschau             0.127219  0.154068  0.139368  0.191074  0.190624   \n",
       "Tagesspiegel           0.156401  0.169185  0.118994  0.166775  0.206165   \n",
       "Telepolis              0.177044  0.110898  0.137713  0.140700  0.216360   \n",
       "Welt                   0.149929  0.135790  0.129040  0.165433  0.207596   \n",
       "WirtschaftsWoche       0.139183  0.131794  0.126319  0.178989  0.221659   \n",
       "Zeit                   0.170910  0.134542  0.115151  0.179987  0.179531   \n",
       "\n",
       "                              5  \n",
       "site                             \n",
       "Deutsche Stimme        0.462288  \n",
       "FAZ                    0.125277  \n",
       "Focus                  0.154171  \n",
       "Frankfurter Rundschau  0.154091  \n",
       "Golem                  0.086722  \n",
       "Handelsblatt           0.143778  \n",
       "Heise                  0.106492  \n",
       "Huffington Post        0.130732  \n",
       "Junge Freiheit         0.240273  \n",
       "Junge Welt             0.141422  \n",
       "N24                    0.113308  \n",
       "NTV                    0.151392  \n",
       "Netzpolitik            0.096869  \n",
       "RP Online              0.119119  \n",
       "Spiegel                0.131184  \n",
       "Stern                  0.125212  \n",
       "Süddeutsche            0.130238  \n",
       "TAZ                    0.119188  \n",
       "Tagesschau             0.100108  \n",
       "Tagesspiegel           0.110606  \n",
       "Telepolis              0.148459  \n",
       "Welt                   0.104321  \n",
       "WirtschaftsWoche       0.110911  \n",
       "Zeit                   0.111111  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KW.groupby('site').median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
