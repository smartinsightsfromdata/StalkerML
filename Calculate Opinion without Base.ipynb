{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Political Opinion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "from os import path\n",
    "from random import shuffle\n",
    "from corputil import FileCorpus, ListCorpus\n",
    "from corputil.utils import load_stopwords\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "\n",
    "stopwords = load_stopwords(path.join('data', 'german.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Base Model\n",
    "\n",
    "Calculate the base model (empty), that is later used as a base for training the classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 79711 words, keeping 18385 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 163674 words, keeping 27963 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 238232 words, keeping 36915 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 310327 words, keeping 43511 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 388556 words, keeping 50598 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 471836 words, keeping 56986 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 552429 words, keeping 62121 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 633607 words, keeping 66555 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 714633 words, keeping 70989 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 796789 words, keeping 75250 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 879203 words, keeping 79212 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 961587 words, keeping 82909 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 1024648 words, keeping 88843 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 1082821 words, keeping 94376 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 1145886 words, keeping 100183 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 1215306 words, keeping 104411 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 1279164 words, keeping 107701 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 1334673 words, keeping 109966 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 1396215 words, keeping 113099 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 1468706 words, keeping 116814 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 1541914 words, keeping 119680 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 1623756 words, keeping 122878 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 1703341 words, keeping 126382 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 1775945 words, keeping 129422 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 1853738 words, keeping 132718 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 1933206 words, keeping 135873 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 2012726 words, keeping 138770 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 2092283 words, keeping 141676 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 2170869 words, keeping 144460 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 2250650 words, keeping 147583 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #310000, processed 2332846 words, keeping 150871 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #320000, processed 2412938 words, keeping 154084 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #330000, processed 2492871 words, keeping 157298 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #340000, processed 2573958 words, keeping 160258 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #350000, processed 2650701 words, keeping 163119 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #360000, processed 2704676 words, keeping 164780 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #370000, processed 2759917 words, keeping 166632 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #380000, processed 2815819 words, keeping 168110 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #390000, processed 2861119 words, keeping 169322 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #400000, processed 2911851 words, keeping 169831 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #410000, processed 2964838 words, keeping 169831 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #420000, processed 3021720 words, keeping 170064 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #430000, processed 3075319 words, keeping 170131 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #440000, processed 3122837 words, keeping 170414 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #450000, processed 3177902 words, keeping 171235 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #460000, processed 3230688 words, keeping 172207 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #470000, processed 3286116 words, keeping 173219 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #480000, processed 3341813 words, keeping 174223 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #490000, processed 3402285 words, keeping 175444 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #500000, processed 3457804 words, keeping 176694 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #510000, processed 3508827 words, keeping 177837 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #520000, processed 3564069 words, keeping 179066 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #530000, processed 3620567 words, keeping 180552 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #540000, processed 3675497 words, keeping 181846 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #550000, processed 3729450 words, keeping 182825 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #560000, processed 3786133 words, keeping 184089 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #570000, processed 3846869 words, keeping 185683 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #580000, processed 3905452 words, keeping 186865 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #590000, processed 3964680 words, keeping 188082 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #600000, processed 4021767 words, keeping 189386 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #610000, processed 4083236 words, keeping 190943 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #620000, processed 4145636 words, keeping 192527 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #630000, processed 4212396 words, keeping 194265 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #640000, processed 4279745 words, keeping 195980 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #650000, processed 4346571 words, keeping 197799 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #660000, processed 4415403 words, keeping 199557 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #670000, processed 4482680 words, keeping 200576 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #680000, processed 4544675 words, keeping 201522 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #690000, processed 4611734 words, keeping 202492 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #700000, processed 4680994 words, keeping 204548 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #710000, processed 4750407 words, keeping 205933 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #720000, processed 4830034 words, keeping 209382 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #730000, processed 4916312 words, keeping 213402 word types\n",
      "INFO:gensim.models.word2vec:collected 213898 word types from a corpus of 4929179 raw words and 731668 sentences\n",
      "INFO:gensim.models.word2vec:min_count=5 retains 63177 unique words (drops 150721)\n",
      "INFO:gensim.models.word2vec:min_count leaves 4681810 word corpus (94% of original 4929179)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 213898 items\n",
      "INFO:gensim.models.word2vec:sample=0 downsamples 0 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 4681810 word corpus (100.0% of prior 4681810)\n",
      "INFO:gensim.models.word2vec:estimated required memory for 63177 words and 200 dimensions: 145307100 bytes\n",
      "INFO:gensim.models.word2vec:constructing a huffman tree from 63177 words\n",
      "INFO:gensim.models.word2vec:built huffman tree with maximum node depth 20\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "spd = [\n",
    "    path.join('data', 'Politics', 'SPD_EU.txt'),\n",
    "    path.join('data', 'Politics', 'SPD_Fraktion.txt'),\n",
    "#     path.join('data', 'Politics', 'SPD_Vorwärts_Inland.txt')\n",
    "#     path.join('data', 'Politics', 'SPD_Vorwärts_International.txt'),\n",
    "    path.join('data', 'Politics', 'SPD_Vorwärts_Parteileben.txt')\n",
    "]\n",
    "\n",
    "linke = [\n",
    "    path.join('data', 'Politics', 'Linke.txt'),\n",
    "    path.join('data', 'Politics', 'Linke_PR.txt')\n",
    "#     path.join('data', 'Politics', 'Linke_Fraktion.txt')\n",
    "]\n",
    "\n",
    "gruene = [\n",
    "    path.join('data', 'Politics', 'Grüne.txt'),\n",
    "    path.join('data', 'Politics', 'Grüne_Fraktion.txt')\n",
    "]\n",
    "\n",
    "fdp = [\n",
    "    path.join('data', 'Politics', 'FDP.txt'),\n",
    "    path.join('data', 'Politics', 'FDP_Fraktion.txt')\n",
    "]\n",
    "\n",
    "cdu = [\n",
    "    path.join('data', 'Politics', 'CDU.txt')\n",
    "#     path.join('data', 'Politics', 'CDU_Fraktion.txt')\n",
    "]\n",
    "\n",
    "npd = [\n",
    "    path.join('data', 'Politics', 'NPD_MV.txt')\n",
    "#     path.join('data', 'Politics', 'NPD_Sachsen.txt'),\n",
    "#     path.join('data', 'Politics', 'NPD_Jung.txt')\n",
    "]\n",
    "\n",
    "files = [file for fp in [spd, linke, gruene, fdp, cdu, npd] for file in fp]\n",
    "\n",
    "base_corpus = list(FileCorpus(files).sentences_token(stopwords=stopwords))\n",
    "base = Word2Vec(workers=4, iter=6, size=200, window=3)\n",
    "base.build_vocab(base_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to disk. Don't finalize the model because we need to train it with new data later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base.save(path.join('models', 'base.w2v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 12.71% examples, 340859 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 25.55% examples, 342220 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 38.48% examples, 343428 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 51.21% examples, 343091 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.05% examples, 343404 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 76.74% examples, 342731 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 87.82% examples, 336115 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 98.41% examples, 329741 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 2834532 raw words took 8.2s, 328910 trained words/s\n",
      "INFO:gensim.models.word2vec:training model with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.76% examples, 370489 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 11.54% examples, 372417 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 17.34% examples, 372634 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 23.15% examples, 372862 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 28.95% examples, 373371 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 34.36% examples, 369171 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 39.46% examples, 363444 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 44.77% examples, 360810 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 49.26% examples, 352727 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 53.12% examples, 342340 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 56.74% examples, 332434 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 60.52% examples, 325058 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.80% examples, 321216 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 69.39% examples, 319380 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 73.63% examples, 316310 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 77.83% examples, 313557 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 82.77% examples, 313759 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 88.19% examples, 315762 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 93.73% examples, 317978 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 99.14% examples, 319488 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 6826626 raw words took 20.2s, 319518 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded corpus with 69350 sentences.\n",
      "Loaded corpus with 148844 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.69% examples, 333883 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 11.91% examples, 348919 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 18.01% examples, 351855 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 24.22% examples, 354427 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 29.90% examples, 350101 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 35.47% examples, 346063 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 40.91% examples, 342230 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 46.80% examples, 342399 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 53.06% examples, 345225 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 59.48% examples, 348286 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 65.51% examples, 348690 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 71.54% examples, 349077 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 77.74% examples, 350139 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 83.65% examples, 349838 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 89.45% examples, 349179 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 95.08% examples, 347954 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 6209832 raw words took 16.8s, 348147 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 130818 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 2.83% examples, 342102 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.70% examples, 343205 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8.54% examples, 343123 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 11.40% examples, 343498 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 14.25% examples, 343328 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 17.14% examples, 344295 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 20.06% examples, 345281 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 22.99% examples, 346110 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 25.87% examples, 346233 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 28.74% examples, 346412 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 31.60% examples, 346179 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 34.47% examples, 346135 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 37.15% examples, 344317 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 40.02% examples, 344374 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 42.67% examples, 342687 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 45.48% examples, 342517 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 48.31% examples, 342416 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 51.15% examples, 342426 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 53.81% examples, 341264 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 56.52% examples, 340477 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 59.24% examples, 339898 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 61.99% examples, 339577 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.78% examples, 339418 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 67.50% examples, 338926 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 70.31% examples, 338883 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 73.14% examples, 338944 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 76.04% examples, 339341 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 78.64% examples, 338473 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 81.25% examples, 337582 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 84.05% examples, 337608 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 86.90% examples, 337796 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 89.73% examples, 337842 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 92.55% examples, 337931 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 95.40% examples, 338135 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 98.24% examples, 338255 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 12593910 raw words took 35.7s, 338322 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 360090 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 119472 raw words took 0.3s, 357087 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 2790 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 41.21% examples, 373132 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 82.42% examples, 373194 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 990702 raw words took 2.4s, 374707 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 19776 sentences.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "corpora = [\n",
    "    FileCorpus(linke),\n",
    "    FileCorpus(spd),\n",
    "    FileCorpus(gruene), \n",
    "    FileCorpus(fdp), \n",
    "    FileCorpus(cdu), \n",
    "    FileCorpus(npd)\n",
    "]\n",
    "models = [deepcopy(base) for i in range(len(corpora))]\n",
    "\n",
    "for i in range(len(corpora)):\n",
    "    sentences = list(corpora[i].sentences_token(stopwords=stopwords))\n",
    "    shuffle(sentences)\n",
    "    models[i].train(sentences, total_examples=len(sentences))\n",
    "    print('Loaded corpus with {} sentences.'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['2015KW44', '2015KW45', '2015KW46', '2015KW47', '2015KW48', '2015KW49', '2015KW50', '2015KW51', \n",
    "          '2015KW52', '2015KW53', '2016KW01']\n",
    "files = [path.join('data', 'CurrentNews', '{}.csv').format(label) for label in labels]\n",
    "output = [path.join('data', 'CurrentNews', 'Sentiment_{}.csv').format(label) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.7s, 99499 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.7s, 97284 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.7s, 97350 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.7s, 96390 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 11 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.7s, 96864 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72146 sentences took 0.8s, 95051 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.7s, 92912 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.6s, 97960 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.6s, 98139 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.6s, 98070 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 11 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.6s, 97866 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63173 sentences took 0.6s, 97547 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10370000.00% sentences, 103666 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.1s, 103334 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10460000.00% sentences, 104589 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.1s, 104055 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10010000.00% sentences, 99988 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.1s, 100033 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10100000.00% sentences, 100851 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.1s, 100858 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10230000.00% sentences, 102271 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.1s, 102116 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10170000.00% sentences, 101683 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 113567 sentences took 1.1s, 101351 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10060000.00% sentences, 100580 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.0s, 100261 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10250000.00% sentences, 102438 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.0s, 102236 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9920000.00% sentences, 99081 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.1s, 98864 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10010000.00% sentences, 100092 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.0s, 99673 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10120000.00% sentences, 101144 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.0s, 100788 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10190000.00% sentences, 101823 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 104160 sentences took 1.0s, 101295 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.9s, 84811 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 86463 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 93629 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 93256 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 91318 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72710 sentences took 0.8s, 90667 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 83293 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.7s, 89879 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.7s, 89797 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.7s, 90007 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.7s, 94743 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 63577 sentences took 0.8s, 81114 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.7s, 101510 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.7s, 98753 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.7s, 98578 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.7s, 97390 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.7s, 98460 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 72195 sentences took 0.7s, 97896 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 96892 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 96402 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 92898 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 91241 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.7s, 100147 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 74536 sentences took 0.8s, 98947 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 99661 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 96801 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 92162 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 98528 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 98053 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 47349 sentences took 0.5s, 97895 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.5s, 96235 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.5s, 99251 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.5s, 96056 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.5s, 96568 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.5s, 96926 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 52354 sentences took 0.5s, 95511 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 100107 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 99339 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 97739 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 96305 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 98638 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 63177 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 78452 sentences took 0.8s, 97460 sentences/s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_score(doc, mod):\n",
    "    model = Word2Vec.load(mod)\n",
    "    score = model.score(doc, len(doc))\n",
    "    return score\n",
    "\n",
    "def calc_probability(df, mods):\n",
    "    docs = list(ListCorpus(list(df.loc[:, 'text'])).doc_sentences_token(stopwords=stopwords))\n",
    "    sentlist = [s for d in docs for s in d]\n",
    "    llhd = np.array( [ m.score(sentlist, len(sentlist)) for m in mods ] )\n",
    "    lhd = np.exp(llhd - llhd.max(axis=0))\n",
    "    prob = pd.DataFrame( (lhd/lhd.sum(axis=0)).transpose() )\n",
    "    prob[\"doc\"] = [i for i,d in enumerate(docs) for s in d]\n",
    "    prob = prob.groupby(\"doc\").mean()\n",
    "    return prob\n",
    "\n",
    "def process(data):\n",
    "    sentiment = calc_probability(data, models)\n",
    "    return sentiment\n",
    "\n",
    "# KW = pd.read_csv(path.join('data', 'CurrentNews', '2015KW45.csv'), sep='|', encoding='utf-8')\n",
    "# prob = calc_probability(KW, models)\n",
    "# # prob = prob.div(prob.sum(axis=1), axis=0)\n",
    "# # prob = prob.sub(.16, axis=0)\n",
    "# KW = pd.concat([KW, prob], axis=1)\n",
    "\n",
    "for file, out in zip(files, output):\n",
    "    data = pd.read_csv(file, sep='|', encoding='utf-8')\n",
    "    sentiment = process(data)\n",
    "    csv = pd.concat([data, sentiment], axis=1)\n",
    "    csv.rename(columns={ 0: 'Linke', 1: 'SPD', 2: 'Gruene', 3: 'FDP', 4: 'CDU', 5: 'NPD'  }, inplace=True)\n",
    "    csv.to_csv(out, index=False, encoding='utf-8', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deutsche Stimme</th>\n",
       "      <td>0.143481</td>\n",
       "      <td>0.152666</td>\n",
       "      <td>0.055975</td>\n",
       "      <td>0.074863</td>\n",
       "      <td>0.127574</td>\n",
       "      <td>0.445442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAZ</th>\n",
       "      <td>0.190342</td>\n",
       "      <td>0.141653</td>\n",
       "      <td>0.139456</td>\n",
       "      <td>0.165006</td>\n",
       "      <td>0.220801</td>\n",
       "      <td>0.142741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focus</th>\n",
       "      <td>0.185337</td>\n",
       "      <td>0.137742</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>0.138990</td>\n",
       "      <td>0.221386</td>\n",
       "      <td>0.188950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frankfurter Rundschau</th>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.141748</td>\n",
       "      <td>0.119125</td>\n",
       "      <td>0.163003</td>\n",
       "      <td>0.242871</td>\n",
       "      <td>0.178719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golem</th>\n",
       "      <td>0.074173</td>\n",
       "      <td>0.218491</td>\n",
       "      <td>0.121137</td>\n",
       "      <td>0.195631</td>\n",
       "      <td>0.267314</td>\n",
       "      <td>0.123253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handelsblatt</th>\n",
       "      <td>0.170205</td>\n",
       "      <td>0.154098</td>\n",
       "      <td>0.134361</td>\n",
       "      <td>0.169581</td>\n",
       "      <td>0.230604</td>\n",
       "      <td>0.141151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heise</th>\n",
       "      <td>0.087215</td>\n",
       "      <td>0.239453</td>\n",
       "      <td>0.144817</td>\n",
       "      <td>0.164097</td>\n",
       "      <td>0.253515</td>\n",
       "      <td>0.110903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huffington Post</th>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.115522</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>0.184880</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>0.147926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Freiheit</th>\n",
       "      <td>0.171560</td>\n",
       "      <td>0.175352</td>\n",
       "      <td>0.089988</td>\n",
       "      <td>0.153248</td>\n",
       "      <td>0.182936</td>\n",
       "      <td>0.226916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Welt</th>\n",
       "      <td>0.275806</td>\n",
       "      <td>0.114122</td>\n",
       "      <td>0.125237</td>\n",
       "      <td>0.116283</td>\n",
       "      <td>0.215179</td>\n",
       "      <td>0.153374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N24</th>\n",
       "      <td>0.177158</td>\n",
       "      <td>0.147912</td>\n",
       "      <td>0.150626</td>\n",
       "      <td>0.169323</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.131960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTV</th>\n",
       "      <td>0.170504</td>\n",
       "      <td>0.140003</td>\n",
       "      <td>0.150601</td>\n",
       "      <td>0.174684</td>\n",
       "      <td>0.209557</td>\n",
       "      <td>0.154652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netzpolitik</th>\n",
       "      <td>0.084514</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.135810</td>\n",
       "      <td>0.191221</td>\n",
       "      <td>0.220576</td>\n",
       "      <td>0.121725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP Online</th>\n",
       "      <td>0.182091</td>\n",
       "      <td>0.137798</td>\n",
       "      <td>0.124951</td>\n",
       "      <td>0.193680</td>\n",
       "      <td>0.198997</td>\n",
       "      <td>0.162483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.173440</td>\n",
       "      <td>0.140598</td>\n",
       "      <td>0.150945</td>\n",
       "      <td>0.168274</td>\n",
       "      <td>0.215020</td>\n",
       "      <td>0.151722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stern</th>\n",
       "      <td>0.268609</td>\n",
       "      <td>0.185611</td>\n",
       "      <td>0.124405</td>\n",
       "      <td>0.189051</td>\n",
       "      <td>0.141122</td>\n",
       "      <td>0.091202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Süddeutsche</th>\n",
       "      <td>0.157466</td>\n",
       "      <td>0.144477</td>\n",
       "      <td>0.123326</td>\n",
       "      <td>0.160968</td>\n",
       "      <td>0.254772</td>\n",
       "      <td>0.158991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAZ</th>\n",
       "      <td>0.185408</td>\n",
       "      <td>0.130009</td>\n",
       "      <td>0.140759</td>\n",
       "      <td>0.174114</td>\n",
       "      <td>0.212006</td>\n",
       "      <td>0.157704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesschau</th>\n",
       "      <td>0.161878</td>\n",
       "      <td>0.161017</td>\n",
       "      <td>0.153973</td>\n",
       "      <td>0.190283</td>\n",
       "      <td>0.203102</td>\n",
       "      <td>0.129748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesspiegel</th>\n",
       "      <td>0.178816</td>\n",
       "      <td>0.165373</td>\n",
       "      <td>0.137726</td>\n",
       "      <td>0.152055</td>\n",
       "      <td>0.227503</td>\n",
       "      <td>0.138527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telepolis</th>\n",
       "      <td>0.226915</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.137112</td>\n",
       "      <td>0.125291</td>\n",
       "      <td>0.226201</td>\n",
       "      <td>0.174882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welt</th>\n",
       "      <td>0.177263</td>\n",
       "      <td>0.150320</td>\n",
       "      <td>0.125888</td>\n",
       "      <td>0.177838</td>\n",
       "      <td>0.221838</td>\n",
       "      <td>0.146853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WirtschaftsWoche</th>\n",
       "      <td>0.153916</td>\n",
       "      <td>0.131782</td>\n",
       "      <td>0.146399</td>\n",
       "      <td>0.205193</td>\n",
       "      <td>0.237966</td>\n",
       "      <td>0.124744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeit</th>\n",
       "      <td>0.156292</td>\n",
       "      <td>0.159597</td>\n",
       "      <td>0.159298</td>\n",
       "      <td>0.172166</td>\n",
       "      <td>0.200694</td>\n",
       "      <td>0.151953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "KW.groupby('site').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Deutsche Stimme</th>\n",
       "      <td>0.134316</td>\n",
       "      <td>0.133785</td>\n",
       "      <td>0.095304</td>\n",
       "      <td>0.076921</td>\n",
       "      <td>0.132382</td>\n",
       "      <td>0.427291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAZ</th>\n",
       "      <td>0.193461</td>\n",
       "      <td>0.132037</td>\n",
       "      <td>0.162553</td>\n",
       "      <td>0.156245</td>\n",
       "      <td>0.209193</td>\n",
       "      <td>0.146512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focus</th>\n",
       "      <td>0.180777</td>\n",
       "      <td>0.129777</td>\n",
       "      <td>0.139876</td>\n",
       "      <td>0.152575</td>\n",
       "      <td>0.212519</td>\n",
       "      <td>0.184477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frankfurter Rundschau</th>\n",
       "      <td>0.163146</td>\n",
       "      <td>0.135052</td>\n",
       "      <td>0.124147</td>\n",
       "      <td>0.149812</td>\n",
       "      <td>0.236434</td>\n",
       "      <td>0.191409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golem</th>\n",
       "      <td>0.066001</td>\n",
       "      <td>0.227060</td>\n",
       "      <td>0.154085</td>\n",
       "      <td>0.136155</td>\n",
       "      <td>0.280229</td>\n",
       "      <td>0.136470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handelsblatt</th>\n",
       "      <td>0.154881</td>\n",
       "      <td>0.147685</td>\n",
       "      <td>0.164981</td>\n",
       "      <td>0.173967</td>\n",
       "      <td>0.206587</td>\n",
       "      <td>0.151899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heise</th>\n",
       "      <td>0.085268</td>\n",
       "      <td>0.204673</td>\n",
       "      <td>0.157906</td>\n",
       "      <td>0.189583</td>\n",
       "      <td>0.257963</td>\n",
       "      <td>0.104608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huffington Post</th>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.112101</td>\n",
       "      <td>0.164072</td>\n",
       "      <td>0.181179</td>\n",
       "      <td>0.211596</td>\n",
       "      <td>0.145445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Freiheit</th>\n",
       "      <td>0.156194</td>\n",
       "      <td>0.160524</td>\n",
       "      <td>0.101973</td>\n",
       "      <td>0.153493</td>\n",
       "      <td>0.195265</td>\n",
       "      <td>0.232551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Welt</th>\n",
       "      <td>0.256230</td>\n",
       "      <td>0.108804</td>\n",
       "      <td>0.155928</td>\n",
       "      <td>0.125893</td>\n",
       "      <td>0.198824</td>\n",
       "      <td>0.154321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N24</th>\n",
       "      <td>0.170696</td>\n",
       "      <td>0.140336</td>\n",
       "      <td>0.175946</td>\n",
       "      <td>0.157886</td>\n",
       "      <td>0.217836</td>\n",
       "      <td>0.137299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTV</th>\n",
       "      <td>0.172514</td>\n",
       "      <td>0.132485</td>\n",
       "      <td>0.170169</td>\n",
       "      <td>0.164891</td>\n",
       "      <td>0.195101</td>\n",
       "      <td>0.164839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netzpolitik</th>\n",
       "      <td>0.098904</td>\n",
       "      <td>0.273127</td>\n",
       "      <td>0.123808</td>\n",
       "      <td>0.186953</td>\n",
       "      <td>0.206483</td>\n",
       "      <td>0.110726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP Online</th>\n",
       "      <td>0.185174</td>\n",
       "      <td>0.118232</td>\n",
       "      <td>0.156567</td>\n",
       "      <td>0.179934</td>\n",
       "      <td>0.195509</td>\n",
       "      <td>0.164584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.165506</td>\n",
       "      <td>0.132483</td>\n",
       "      <td>0.160803</td>\n",
       "      <td>0.176316</td>\n",
       "      <td>0.214438</td>\n",
       "      <td>0.150454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stern</th>\n",
       "      <td>0.222549</td>\n",
       "      <td>0.158375</td>\n",
       "      <td>0.261190</td>\n",
       "      <td>0.139629</td>\n",
       "      <td>0.124859</td>\n",
       "      <td>0.093398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Süddeutsche</th>\n",
       "      <td>0.154680</td>\n",
       "      <td>0.133367</td>\n",
       "      <td>0.151083</td>\n",
       "      <td>0.151237</td>\n",
       "      <td>0.239947</td>\n",
       "      <td>0.169686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAZ</th>\n",
       "      <td>0.178889</td>\n",
       "      <td>0.126083</td>\n",
       "      <td>0.177130</td>\n",
       "      <td>0.155627</td>\n",
       "      <td>0.198345</td>\n",
       "      <td>0.163926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesschau</th>\n",
       "      <td>0.147928</td>\n",
       "      <td>0.146715</td>\n",
       "      <td>0.189848</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>0.206395</td>\n",
       "      <td>0.122141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesspiegel</th>\n",
       "      <td>0.164168</td>\n",
       "      <td>0.164485</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>0.214282</td>\n",
       "      <td>0.136718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telepolis</th>\n",
       "      <td>0.212019</td>\n",
       "      <td>0.110382</td>\n",
       "      <td>0.162285</td>\n",
       "      <td>0.128202</td>\n",
       "      <td>0.220845</td>\n",
       "      <td>0.166268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welt</th>\n",
       "      <td>0.174916</td>\n",
       "      <td>0.140215</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.176491</td>\n",
       "      <td>0.212828</td>\n",
       "      <td>0.145151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WirtschaftsWoche</th>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.117680</td>\n",
       "      <td>0.168138</td>\n",
       "      <td>0.192659</td>\n",
       "      <td>0.232447</td>\n",
       "      <td>0.140009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeit</th>\n",
       "      <td>0.171992</td>\n",
       "      <td>0.146805</td>\n",
       "      <td>0.167467</td>\n",
       "      <td>0.174663</td>\n",
       "      <td>0.187515</td>\n",
       "      <td>0.151558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "KW.groupby('site').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}