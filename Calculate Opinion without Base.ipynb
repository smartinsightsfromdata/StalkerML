{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Political Opinion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s')\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "from os import path\n",
    "from corputil import FileCorpus, ListCorpus\n",
    "from corputil.utils import load_stopwords\n",
    "from gensim.models.word2vec import LineSentence, Word2Vec\n",
    "\n",
    "stopwords = load_stopwords(path.join('data', 'german.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Base Model\n",
    "\n",
    "Calculate the base model (empty), that is later used as a base for training the classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 82452 words, keeping 18390 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 168831 words, keeping 27968 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 244315 words, keeping 36920 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 316825 words, keeping 43516 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 395523 words, keeping 50603 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 479198 words, keeping 56991 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 560202 words, keeping 62126 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 641777 words, keeping 66560 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 723299 words, keeping 70994 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 805814 words, keeping 75255 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 888570 words, keeping 79217 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 971360 words, keeping 82914 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 1034649 words, keeping 88849 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 1092980 words, keeping 94382 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 1156853 words, keeping 100139 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 1227958 words, keeping 103995 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 1309688 words, keeping 107850 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 1390442 words, keeping 111709 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 1466496 words, keeping 115306 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 1541822 words, keeping 118508 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 1621773 words, keeping 122165 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 1701958 words, keeping 125332 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 1781531 words, keeping 128365 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 1861573 words, keeping 131461 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 1940411 words, keeping 134413 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 2021959 words, keeping 137892 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 2104723 words, keeping 141341 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 2184746 words, keeping 144724 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 2266326 words, keeping 147895 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 2346413 words, keeping 151043 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #310000, processed 2411374 words, keeping 153387 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #320000, processed 2464788 words, keeping 155223 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #330000, processed 2522035 words, keeping 157010 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #340000, processed 2573219 words, keeping 158462 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #350000, processed 2619673 words, keeping 159674 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #360000, processed 2673984 words, keeping 159675 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #370000, processed 2729495 words, keeping 159752 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #380000, processed 2786886 words, keeping 159965 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #390000, processed 2835255 words, keeping 160108 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #400000, processed 2886250 words, keeping 160629 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #410000, processed 2938636 words, keeping 161675 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #420000, processed 2993828 words, keeping 162745 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #430000, processed 3049665 words, keeping 163670 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #440000, processed 3109884 words, keeping 164753 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #450000, processed 3167922 words, keeping 166268 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #460000, processed 3221311 words, keeping 167454 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #470000, processed 3277729 words, keeping 168791 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #480000, processed 3331266 words, keeping 170143 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #490000, processed 3387848 words, keeping 171613 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #500000, processed 3443500 words, keeping 172904 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #510000, processed 3499189 words, keeping 173980 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #520000, processed 3558887 words, keeping 175765 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #530000, processed 3617089 words, keeping 176981 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #540000, processed 3676890 words, keeping 178164 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #550000, processed 3733339 words, keeping 179464 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #560000, processed 3793129 words, keeping 180936 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #570000, processed 3856503 words, keeping 182592 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #580000, processed 3922248 words, keeping 184467 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #590000, processed 3988662 words, keeping 186198 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #600000, processed 4056618 words, keeping 187917 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #610000, processed 4123590 words, keeping 189863 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #620000, processed 4193883 words, keeping 191402 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #630000, processed 4259342 words, keeping 192282 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #640000, processed 4323549 words, keeping 193215 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #650000, processed 4390177 words, keeping 194845 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #660000, processed 4461656 words, keeping 196786 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #670000, processed 4533450 words, keeping 198219 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #680000, processed 4610191 words, keeping 200395 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #690000, processed 4686524 words, keeping 202846 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #700000, processed 4763820 words, keeping 204859 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #710000, processed 4839919 words, keeping 206745 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #720000, processed 4916198 words, keeping 208876 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #730000, processed 4996784 words, keeping 210679 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #740000, processed 5079346 words, keeping 214408 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #750000, processed 5164696 words, keeping 218364 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #760000, processed 5270053 words, keeping 222905 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #770000, processed 5381015 words, keeping 227479 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #780000, processed 5491651 words, keeping 231813 word types\n",
      "INFO:gensim.models.word2vec:collected 232195 word types from a corpus of 5504419 raw words and 781238 sentences\n",
      "INFO:gensim.models.word2vec:min_count=5 retains 68366 unique words (drops 163829)\n",
      "INFO:gensim.models.word2vec:min_count leaves 5235880 word corpus (95% of original 5504419)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 232195 items\n",
      "INFO:gensim.models.word2vec:sample=0 downsamples 0 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 5235880 word corpus (100.0% of prior 5235880)\n",
      "INFO:gensim.models.word2vec:estimated required memory for 68366 words and 200 dimensions: 157241800 bytes\n",
      "INFO:gensim.models.word2vec:constructing a huffman tree from 68366 words\n",
      "INFO:gensim.models.word2vec:built huffman tree with maximum node depth 20\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "from corputil import FileCorpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "spd = [\n",
    "    path.join('data', 'Politics', 'SPD_EU.txt'),\n",
    "    path.join('data', 'Politics', 'SPD_Fraktion.txt'),\n",
    "#    path.join('data', 'Politics', 'SPD_Vorwärts_Inland.txt'),\n",
    "#    path.join('data', 'Politics', 'SPD_Vorwärts_International.txt'),\n",
    "    path.join('data', 'Politics', 'SPD_Vorwärts_Parteileben.txt')\n",
    "]\n",
    "\n",
    "linke = [\n",
    "#     path.join('data', 'Politics', 'Linke.txt'),\n",
    "    path.join('data', 'Politics', 'Linke_PR.txt'),\n",
    "#     path.join('data', 'Politics', 'Linke_Fraktion.txt')\n",
    "]\n",
    "\n",
    "gruene = [\n",
    "    path.join('data', 'Politics', 'Grüne.txt'),\n",
    "    path.join('data', 'Politics', 'Grüne_Fraktion.txt')\n",
    "]\n",
    "\n",
    "fdp = [\n",
    "    path.join('data', 'Politics', 'FDP.txt'),\n",
    "    path.join('data', 'Politics', 'FDP_Fraktion.txt')\n",
    "]\n",
    "\n",
    "cdu = [\n",
    "    path.join('data', 'Politics', 'CDU.txt'),\n",
    "    path.join('data', 'Politics', 'CDU_Fraktion.txt')\n",
    "]\n",
    "\n",
    "npd = [\n",
    "    path.join('data', 'Politics', 'NPD_MV.txt'),\n",
    "    path.join('data', 'Politics', 'NPD_Sachsen.txt')\n",
    "#     path.join('data', 'Politics', 'NPD_Jung.txt')\n",
    "]\n",
    "\n",
    "files = [file for fp in [spd, linke, gruene, fdp, cdu, npd] for file in fp]\n",
    "\n",
    "base_corpus = list(FileCorpus(files).sentences_token(stopwords=stopwords))\n",
    "base = Word2Vec(workers=4, iter=4, size=200, window=10)\n",
    "base.build_vocab(base_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model to disk. Don't finalize the model because we need to train it with new data later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# base.save(path.join('models', 'base.w2v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.58% examples, 253557 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 11.30% examples, 256422 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 16.80% examples, 256083 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 22.46% examples, 250950 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 28.27% examples, 248763 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 33.91% examples, 247947 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 38.51% examples, 243325 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 42.53% examples, 236374 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 48.24% examples, 235301 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 52.94% examples, 231796 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 57.43% examples, 228001 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 62.13% examples, 227356 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 67.27% examples, 228279 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 73.13% examples, 228768 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 78.79% examples, 229771 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 84.25% examples, 230071 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 89.30% examples, 230413 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 93.59% examples, 228717 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 4592344 raw words took 19.0s, 229657 trained words/s\n",
      "INFO:gensim.models.word2vec:training model with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 31.36% examples, 221181 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.67% examples, 227144 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 97.68% examples, 231627 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 749636 raw words took 3.1s, 231754 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded corpus with 148844 sentences.\n",
      "Loaded corpus with 24315 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 4.83% examples, 183982 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 9.92% examples, 192715 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 15.84% examples, 206607 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 21.44% examples, 211151 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 27.79% examples, 218849 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 34.11% examples, 223197 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 39.52% examples, 221748 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 44.87% examples, 220961 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 50.81% examples, 222592 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 56.89% examples, 223652 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 63.18% examples, 226027 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 68.38% examples, 224606 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 73.96% examples, 224406 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 80.21% examples, 225505 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 86.13% examples, 226069 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 90.55% examples, 222835 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 96.13% examples, 222862 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 4170884 raw words took 17.7s, 223451 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 130818 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 3.09% examples, 224782 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 5.40% examples, 201940 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 8.18% examples, 201231 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 10.71% examples, 201111 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 13.48% examples, 202751 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 16.41% examples, 208472 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 19.15% examples, 211718 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 21.67% examples, 214655 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 24.42% examples, 218790 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 27.78% examples, 223034 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 30.58% examples, 221938 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 33.92% examples, 223819 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 37.32% examples, 226968 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 40.57% examples, 229056 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 43.37% examples, 229034 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 45.49% examples, 226723 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 48.06% examples, 227242 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 50.90% examples, 228601 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 54.40% examples, 230079 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 57.90% examples, 231548 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 61.20% examples, 232736 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.57% examples, 234004 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 67.75% examples, 235058 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 70.52% examples, 235649 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 73.27% examples, 236307 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 76.18% examples, 236916 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 79.69% examples, 237740 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 83.22% examples, 238514 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 86.38% examples, 238831 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 89.72% examples, 239439 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 92.84% examples, 239915 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 95.62% examples, 240242 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 98.34% examples, 240538 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 8444804 raw words took 33.7s, 240696 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 360090 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 12.82% examples, 249325 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 25.72% examples, 251647 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 38.77% examples, 252570 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 51.60% examples, 252584 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 64.68% examples, 253080 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 77.47% examples, 252931 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 90.56% examples, 253264 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 2066628 raw words took 7.8s, 252943 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 67057 sentences."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:training model with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 13.67% examples, 228695 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 24.34% examples, 222867 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 38.36% examples, 227120 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 49.29% examples, 226032 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 63.31% examples, 227678 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 74.13% examples, 226404 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 88.05% examples, 227432 words/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 98.82% examples, 226509 words/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:training on 1993380 raw words took 8.1s, 226404 trained words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded corpus with 50114 sentences.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "corpora = [\n",
    "    FileCorpus(spd), \n",
    "    FileCorpus(linke), \n",
    "    FileCorpus(gruene), \n",
    "    FileCorpus(fdp), \n",
    "    FileCorpus(cdu), \n",
    "    FileCorpus(npd)\n",
    "]\n",
    "models = [deepcopy(base) for i in range(len(corpora))]\n",
    "\n",
    "for i in range(len(corpora)):\n",
    "    sentences = list(corpora[i].sentences_token(stopwords=stopwords))\n",
    "    models[i].train(sentences, total_examples=len(sentences))\n",
    "    print('Loaded corpus with {} sentences.'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 6320000.00% sentences, 63166 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 12350000.00% sentences, 61713 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 19480000.00% sentences, 64906 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 26580000.00% sentences, 66416 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 33480000.00% sentences, 66928 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 39530000.00% sentences, 65853 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 46040000.00% sentences, 65734 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 52890000.00% sentences, 66072 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 60380000.00% sentences, 67038 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 67530000.00% sentences, 67480 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 694761 sentences took 10.3s, 67553 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 7200000.00% sentences, 71811 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 14370000.00% sentences, 71657 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 21920000.00% sentences, 72896 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 28910000.00% sentences, 72127 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 35920000.00% sentences, 71715 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 42420000.00% sentences, 70587 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 48880000.00% sentences, 69728 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 55570000.00% sentences, 69372 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 62880000.00% sentences, 69775 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 694761 sentences took 10.0s, 69718 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 7020000.00% sentences, 70166 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 13460000.00% sentences, 67246 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 20580000.00% sentences, 68503 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 27860000.00% sentences, 69546 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 35030000.00% sentences, 69975 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 41940000.00% sentences, 69797 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 48160000.00% sentences, 68693 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 54750000.00% sentences, 68343 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 62000000.00% sentences, 68783 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 69020000.00% sentences, 68921 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 694761 sentences took 10.1s, 68860 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 6590000.00% sentences, 65791 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 13320000.00% sentences, 66542 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 20800000.00% sentences, 69244 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 28000000.00% sentences, 69921 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 35090000.00% sentences, 70112 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 41750000.00% sentences, 69519 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 47970000.00% sentences, 68464 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 54560000.00% sentences, 68130 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 62210000.00% sentences, 69050 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 68870000.00% sentences, 68798 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 694761 sentences took 10.1s, 68822 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 7150000.00% sentences, 71398 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 14110000.00% sentences, 70496 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 21310000.00% sentences, 70996 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 27780000.00% sentences, 69376 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 34540000.00% sentences, 69020 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 41350000.00% sentences, 68866 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 47770000.00% sentences, 68197 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 54400000.00% sentences, 67957 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 61410000.00% sentences, 68191 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 68480000.00% sentences, 68436 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 694761 sentences took 10.2s, 68404 sentences/s\n",
      "INFO:gensim.models.word2vec:scoring sentences with 4 workers on 68366 vocabulary and 200 features, using sg=1 hs=1 sample=0 and negative=0\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 6610000.00% sentences, 66024 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 13550000.00% sentences, 67693 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 20710000.00% sentences, 68954 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 27640000.00% sentences, 69013 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 33930000.00% sentences, 67748 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 40650000.00% sentences, 67629 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 47070000.00% sentences, 67111 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 53730000.00% sentences, 67047 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 60690000.00% sentences, 67329 sentences/s\n",
      "INFO:gensim.models.word2vec:PROGRESS: at 67680000.00% sentences, 67584 sentences/s\n",
      "INFO:gensim.models.word2vec:reached end of input; waiting to finish 12 outstanding jobs\n",
      "INFO:gensim.models.word2vec:scoring 694761 sentences took 10.3s, 67672 sentences/s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calc_score(doc, mod):\n",
    "    model = Word2Vec.load(mod)\n",
    "    score = model.score(doc, len(doc))\n",
    "    return score\n",
    "\n",
    "def calc_probability(df, mods):\n",
    "    docs = list(ListCorpus(list(df.loc[:, 'text'])).doc_sentences_token(stopwords=stopwords))\n",
    "    sentlist = [s for d in docs for s in d]\n",
    "    llhd = np.array( [ m.score(sentlist, len(sentlist)) for m in mods ] )\n",
    "    lhd = np.exp(llhd - llhd.max(axis=0))\n",
    "    prob = pd.DataFrame( (lhd/lhd.sum(axis=0)).transpose() )\n",
    "    prob[\"doc\"] = [i for i,d in enumerate(docs) for s in d]\n",
    "    prob = prob.groupby(\"doc\").mean()\n",
    "    return prob\n",
    "\n",
    "KW = pd.read_csv(path.join('data', 'CurrentNews', 'All.csv'), sep='|', encoding='utf-8')\n",
    "prob = calc_probability(KW, models)\n",
    "prob = prob.div(prob.sum(axis=1), axis=0)\n",
    "KW = pd.concat([KW, prob], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Berliner Zeitung</th>\n",
       "      <td>0.031824</td>\n",
       "      <td>0.330987</td>\n",
       "      <td>0.296954</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.332794</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bild</th>\n",
       "      <td>0.121541</td>\n",
       "      <td>0.166916</td>\n",
       "      <td>0.177776</td>\n",
       "      <td>0.182734</td>\n",
       "      <td>0.144807</td>\n",
       "      <td>0.206226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Der Postillon</th>\n",
       "      <td>0.109747</td>\n",
       "      <td>0.261821</td>\n",
       "      <td>0.112888</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.133038</td>\n",
       "      <td>0.250568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deutsche Stimme</th>\n",
       "      <td>0.074891</td>\n",
       "      <td>0.170481</td>\n",
       "      <td>0.085498</td>\n",
       "      <td>0.130910</td>\n",
       "      <td>0.071609</td>\n",
       "      <td>0.466610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FAZ</th>\n",
       "      <td>0.149475</td>\n",
       "      <td>0.179004</td>\n",
       "      <td>0.144852</td>\n",
       "      <td>0.187633</td>\n",
       "      <td>0.140829</td>\n",
       "      <td>0.198206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Focus</th>\n",
       "      <td>0.134077</td>\n",
       "      <td>0.186887</td>\n",
       "      <td>0.145099</td>\n",
       "      <td>0.169210</td>\n",
       "      <td>0.153742</td>\n",
       "      <td>0.210984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frankfurter Rundschau</th>\n",
       "      <td>0.141775</td>\n",
       "      <td>0.184357</td>\n",
       "      <td>0.150008</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>0.134988</td>\n",
       "      <td>0.208097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golem</th>\n",
       "      <td>0.236410</td>\n",
       "      <td>0.109015</td>\n",
       "      <td>0.193146</td>\n",
       "      <td>0.198986</td>\n",
       "      <td>0.123087</td>\n",
       "      <td>0.139356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handelsblatt</th>\n",
       "      <td>0.152741</td>\n",
       "      <td>0.179764</td>\n",
       "      <td>0.171003</td>\n",
       "      <td>0.180354</td>\n",
       "      <td>0.147345</td>\n",
       "      <td>0.168793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heise</th>\n",
       "      <td>0.227769</td>\n",
       "      <td>0.130647</td>\n",
       "      <td>0.192854</td>\n",
       "      <td>0.170791</td>\n",
       "      <td>0.138660</td>\n",
       "      <td>0.139278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huffington Post</th>\n",
       "      <td>0.137597</td>\n",
       "      <td>0.192167</td>\n",
       "      <td>0.140323</td>\n",
       "      <td>0.196328</td>\n",
       "      <td>0.131341</td>\n",
       "      <td>0.202245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Freiheit</th>\n",
       "      <td>0.122483</td>\n",
       "      <td>0.161453</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>0.151557</td>\n",
       "      <td>0.096262</td>\n",
       "      <td>0.358049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Junge Welt</th>\n",
       "      <td>0.117227</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>0.157130</td>\n",
       "      <td>0.139574</td>\n",
       "      <td>0.109423</td>\n",
       "      <td>0.214827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitteldeutsche Zeitung</th>\n",
       "      <td>0.161233</td>\n",
       "      <td>0.184935</td>\n",
       "      <td>0.159137</td>\n",
       "      <td>0.169512</td>\n",
       "      <td>0.134027</td>\n",
       "      <td>0.191156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N24</th>\n",
       "      <td>0.141865</td>\n",
       "      <td>0.186463</td>\n",
       "      <td>0.150351</td>\n",
       "      <td>0.175795</td>\n",
       "      <td>0.144846</td>\n",
       "      <td>0.200680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTV</th>\n",
       "      <td>0.137326</td>\n",
       "      <td>0.180677</td>\n",
       "      <td>0.171775</td>\n",
       "      <td>0.184825</td>\n",
       "      <td>0.143834</td>\n",
       "      <td>0.181563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netzpolitik</th>\n",
       "      <td>0.224073</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.199912</td>\n",
       "      <td>0.210750</td>\n",
       "      <td>0.105237</td>\n",
       "      <td>0.139030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RP Online</th>\n",
       "      <td>0.144166</td>\n",
       "      <td>0.167679</td>\n",
       "      <td>0.149127</td>\n",
       "      <td>0.217321</td>\n",
       "      <td>0.133504</td>\n",
       "      <td>0.188203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RT</th>\n",
       "      <td>0.089208</td>\n",
       "      <td>0.176230</td>\n",
       "      <td>0.225325</td>\n",
       "      <td>0.188028</td>\n",
       "      <td>0.166704</td>\n",
       "      <td>0.154505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spiegel</th>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.170650</td>\n",
       "      <td>0.171042</td>\n",
       "      <td>0.186769</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.189492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stern</th>\n",
       "      <td>0.160814</td>\n",
       "      <td>0.180548</td>\n",
       "      <td>0.152296</td>\n",
       "      <td>0.181645</td>\n",
       "      <td>0.140304</td>\n",
       "      <td>0.184393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Süddeutsche</th>\n",
       "      <td>0.153490</td>\n",
       "      <td>0.172343</td>\n",
       "      <td>0.157619</td>\n",
       "      <td>0.193198</td>\n",
       "      <td>0.125687</td>\n",
       "      <td>0.197663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAZ</th>\n",
       "      <td>0.143675</td>\n",
       "      <td>0.187434</td>\n",
       "      <td>0.176787</td>\n",
       "      <td>0.170134</td>\n",
       "      <td>0.119451</td>\n",
       "      <td>0.202520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesschau</th>\n",
       "      <td>0.155634</td>\n",
       "      <td>0.165983</td>\n",
       "      <td>0.170158</td>\n",
       "      <td>0.203865</td>\n",
       "      <td>0.142014</td>\n",
       "      <td>0.162345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tagesspiegel</th>\n",
       "      <td>0.172454</td>\n",
       "      <td>0.195997</td>\n",
       "      <td>0.129103</td>\n",
       "      <td>0.192525</td>\n",
       "      <td>0.120510</td>\n",
       "      <td>0.189411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telepolis</th>\n",
       "      <td>0.117651</td>\n",
       "      <td>0.233110</td>\n",
       "      <td>0.170990</td>\n",
       "      <td>0.158526</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.200839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Titanic</th>\n",
       "      <td>0.079082</td>\n",
       "      <td>0.150065</td>\n",
       "      <td>0.144029</td>\n",
       "      <td>0.231608</td>\n",
       "      <td>0.067799</td>\n",
       "      <td>0.327418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vice</th>\n",
       "      <td>0.114216</td>\n",
       "      <td>0.221822</td>\n",
       "      <td>0.108523</td>\n",
       "      <td>0.152048</td>\n",
       "      <td>0.100980</td>\n",
       "      <td>0.302411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volksstimme</th>\n",
       "      <td>0.170967</td>\n",
       "      <td>0.217980</td>\n",
       "      <td>0.079594</td>\n",
       "      <td>0.206318</td>\n",
       "      <td>0.134832</td>\n",
       "      <td>0.190309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAZ</th>\n",
       "      <td>0.149707</td>\n",
       "      <td>0.177047</td>\n",
       "      <td>0.163780</td>\n",
       "      <td>0.179029</td>\n",
       "      <td>0.149149</td>\n",
       "      <td>0.181289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welt</th>\n",
       "      <td>0.147612</td>\n",
       "      <td>0.195021</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.181172</td>\n",
       "      <td>0.129919</td>\n",
       "      <td>0.198634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WirtschaftsWoche</th>\n",
       "      <td>0.152803</td>\n",
       "      <td>0.201060</td>\n",
       "      <td>0.154284</td>\n",
       "      <td>0.199877</td>\n",
       "      <td>0.124846</td>\n",
       "      <td>0.167130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeit</th>\n",
       "      <td>0.149393</td>\n",
       "      <td>0.178744</td>\n",
       "      <td>0.162148</td>\n",
       "      <td>0.195485</td>\n",
       "      <td>0.132367</td>\n",
       "      <td>0.181864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0         1         2         3         4  \\\n",
       "site                                                                       \n",
       "Berliner Zeitung        0.031824  0.330987  0.296954  0.003738  0.332794   \n",
       "Bild                    0.121541  0.166916  0.177776  0.182734  0.144807   \n",
       "Der Postillon           0.109747  0.261821  0.112888  0.131939  0.133038   \n",
       "Deutsche Stimme         0.074891  0.170481  0.085498  0.130910  0.071609   \n",
       "FAZ                     0.149475  0.179004  0.144852  0.187633  0.140829   \n",
       "Focus                   0.134077  0.186887  0.145099  0.169210  0.153742   \n",
       "Frankfurter Rundschau   0.141775  0.184357  0.150008  0.180776  0.134988   \n",
       "Golem                   0.236410  0.109015  0.193146  0.198986  0.123087   \n",
       "Handelsblatt            0.152741  0.179764  0.171003  0.180354  0.147345   \n",
       "Heise                   0.227769  0.130647  0.192854  0.170791  0.138660   \n",
       "Huffington Post         0.137597  0.192167  0.140323  0.196328  0.131341   \n",
       "Junge Freiheit          0.122483  0.161453  0.110196  0.151557  0.096262   \n",
       "Junge Welt              0.117227  0.261819  0.157130  0.139574  0.109423   \n",
       "Mitteldeutsche Zeitung  0.161233  0.184935  0.159137  0.169512  0.134027   \n",
       "N24                     0.141865  0.186463  0.150351  0.175795  0.144846   \n",
       "NTV                     0.137326  0.180677  0.171775  0.184825  0.143834   \n",
       "Netzpolitik             0.224073  0.120999  0.199912  0.210750  0.105237   \n",
       "RP Online               0.144166  0.167679  0.149127  0.217321  0.133504   \n",
       "RT                      0.089208  0.176230  0.225325  0.188028  0.166704   \n",
       "Spiegel                 0.145299  0.170650  0.171042  0.186769  0.136748   \n",
       "Stern                   0.160814  0.180548  0.152296  0.181645  0.140304   \n",
       "Süddeutsche             0.153490  0.172343  0.157619  0.193198  0.125687   \n",
       "TAZ                     0.143675  0.187434  0.176787  0.170134  0.119451   \n",
       "Tagesschau              0.155634  0.165983  0.170158  0.203865  0.142014   \n",
       "Tagesspiegel            0.172454  0.195997  0.129103  0.192525  0.120510   \n",
       "Telepolis               0.117651  0.233110  0.170990  0.158526  0.118884   \n",
       "Titanic                 0.079082  0.150065  0.144029  0.231608  0.067799   \n",
       "Vice                    0.114216  0.221822  0.108523  0.152048  0.100980   \n",
       "Volksstimme             0.170967  0.217980  0.079594  0.206318  0.134832   \n",
       "WAZ                     0.149707  0.177047  0.163780  0.179029  0.149149   \n",
       "Welt                    0.147612  0.195021  0.147642  0.181172  0.129919   \n",
       "WirtschaftsWoche        0.152803  0.201060  0.154284  0.199877  0.124846   \n",
       "Zeit                    0.149393  0.178744  0.162148  0.195485  0.132367   \n",
       "\n",
       "                               5  \n",
       "site                              \n",
       "Berliner Zeitung        0.003703  \n",
       "Bild                    0.206226  \n",
       "Der Postillon           0.250568  \n",
       "Deutsche Stimme         0.466610  \n",
       "FAZ                     0.198206  \n",
       "Focus                   0.210984  \n",
       "Frankfurter Rundschau   0.208097  \n",
       "Golem                   0.139356  \n",
       "Handelsblatt            0.168793  \n",
       "Heise                   0.139278  \n",
       "Huffington Post         0.202245  \n",
       "Junge Freiheit          0.358049  \n",
       "Junge Welt              0.214827  \n",
       "Mitteldeutsche Zeitung  0.191156  \n",
       "N24                     0.200680  \n",
       "NTV                     0.181563  \n",
       "Netzpolitik             0.139030  \n",
       "RP Online               0.188203  \n",
       "RT                      0.154505  \n",
       "Spiegel                 0.189492  \n",
       "Stern                   0.184393  \n",
       "Süddeutsche             0.197663  \n",
       "TAZ                     0.202520  \n",
       "Tagesschau              0.162345  \n",
       "Tagesspiegel            0.189411  \n",
       "Telepolis               0.200839  \n",
       "Titanic                 0.327418  \n",
       "Vice                    0.302411  \n",
       "Volksstimme             0.190309  \n",
       "WAZ                     0.181289  \n",
       "Welt                    0.198634  \n",
       "WirtschaftsWoche        0.167130  \n",
       "Zeit                    0.181864  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KW.groupby('site').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
